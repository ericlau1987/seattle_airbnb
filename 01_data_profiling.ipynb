{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run data_profiling.ipynb\n",
    "%run data_transformation.ipynb\n",
    "%run package_import.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kaggle (https://www.kaggle.com/airbnb/seattle/data)\n",
    "\n",
    "***Content***\n",
    "\n",
    "The following Airbnb activity is included in this Seattle dataset:\n",
    "\n",
    "***Listings***, including full descriptions and average review score\n",
    "\n",
    "***Reviews***, including unique id for each reviewer and detailed comments\n",
    "\n",
    "***Calendar***, including listing id and the price and availability for that day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read calendar.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_calendar = pd.read_csv('Seattle_Airbnb/calendar.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data profiling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rows and columns\n",
    "\n",
    "* Number of rows are 1,393,570\n",
    "* Number of columns are 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "populate_rows_columns(df_calendar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data quality check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Only the column \"price\" has null values, accounting for 33%. Rows with Null values in column \"price\" are to be deleted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the column price from string to float\n",
    "df_calendar['price'] = transform_prices_column(df_calendar,'price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the column price from string to float\n",
    "try:\n",
    "    # remove \"$\" and \",\" before converting the column \"price\" from string into float\n",
    "    df_calendar['date'] = pd.to_datetime(df_calendar['date'])\n",
    "#     df_calendar['date'] =  df_calendar['date'].dt.date\n",
    "\n",
    "except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_data_profiling(df_calendar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check outliers\n",
    "\n",
    "* Number of rows with price less than the minimum outlier value (-52.5): 0 rows\n",
    "* Number of rows with price greater than the maximum outlier value (287.5): 66,000 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "populate_outlier(df_calendar, 'price')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* boxplot showing outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_calendar.boxplot(column=['price'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### check prices identified as outliers to see whether they are actual outliers or not\n",
    "\n",
    "* check how many rows with outliers vs no outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_outliers = populate_outlier(df_calendar, 'price')\n",
    "# outlier_max_value = df_outliers.iloc[1,0]\n",
    "# df_calendar['date'] = pd.to_datetime(df_calendar['date'])\n",
    "# df_calendar['month']= df_calendar['date'].dt.month\n",
    "\n",
    "# df_calendar['outlier_flag'] = df_calendar['price'].apply(lambda x: 1 if pd.notna(x) and x>outlier_max_value else 0)\n",
    "\n",
    "# # monthly_price = df_calendar[(df_calendar['price'].notna())].groupby(by=['date'], as_index=False)['price'].count()\n",
    "# daily_price = df_calendar[(df_calendar['price'].notna())].groupby(by=['date'], as_index=False).agg({'outlier_flag': ['count', 'sum']})\n",
    "# daily_price.columns = ['date', 'rows', 'outliers']\n",
    "# daily_price['%_outliers'] = daily_price['outliers']/daily_price['rows']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# fig, ax = plt.subplots(figsize=(25,10))\n",
    "# daily_price.plot.bar(x='date', y='%_outliers', ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = daily_price['rows']\n",
    "# y = daily_price['outliers']\n",
    "# text = daily_price['date'].dt.date\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(25,20))\n",
    "# ax.scatter(x, y)\n",
    "# plt.title('Total number of prices vs outliers')\n",
    "# plt.xlabel('# prices ')\n",
    "# plt.ylabel('# outliers')\n",
    "# for i, txt in enumerate(text):\n",
    "#     ax.annotate(txt, (x[i],y[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Duplication\n",
    "\n",
    "* There are no duplicated rows found for all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_duplication(df_calendar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read listings.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_listings = pd.read_csv(r'Seattle_Airbnb/listings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df_listings['experiences_offered'] = df_listings['experiences_offered'].replace(\"none\", np.nan)\n",
    "    \n",
    "except:\n",
    "    pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_listings['price'] = transform_prices_column(df_listings,'price')\n",
    "df_listings['weekly_price'] = transform_prices_column(df_listings,'weekly_price')\n",
    "df_listings['monthly_price'] = transform_prices_column(df_listings,'monthly_price')\n",
    "df_listings['security_deposit'] = transform_prices_column(df_listings,'security_deposit')\n",
    "df_listings['cleaning_fee'] = transform_prices_column(df_listings,'cleaning_fee')\n",
    "df_listings['extra_people'] = transform_prices_column(df_listings,'extra_people')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data profiling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ***Null values***: the column \"license\" and \"experiences_offered\" are 100% null values; the column \"square_feet\" has 97% null values. For the columns with over 97% null values, they need to be removed in ETL\n",
    "* ***only one unique value***: ['scrape_id', 'last_scraped', 'experiences_offered', 'market', 'country_code', 'country', 'has_availability', 'calendar_last_scraped',\n",
    " 'requires_license',\n",
    " 'license',\n",
    " 'jurisdiction_names']. They might be not useful and need to be removed in ETL process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_listings_profiling = main_data_profiling(df_listings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print data profiling for all columns\n",
    "df_listings_profiling.sort_values(by=['column_names'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### null value check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list 100% null values\n",
    "list(df_listings_profiling.loc[df_listings_profiling['%_null_values'] == 1, 'column_names'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### only one unique value check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# list columns with only one unique value\n",
    "list(df_listings_profiling[df_listings_profiling['unique_count'] == 1].columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### use boxplot to check the columns with outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers_col = list(df_listings_profiling.loc[(df_listings_profiling['num_lower_outliers'].notna()) & (df_listings_profiling['num_higher_outliers'].notna()) & ( (df_listings_profiling['num_lower_outliers']>0) | (df_listings_profiling['num_higher_outliers']>0) ), 'column_names'])\n",
    "boxplot_outliers(df_listings, outliers_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_duplication(df_listings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read reviews.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews = pd.read_csv(r'Seattle_Airbnb/reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "populate_rows_columns(df_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews['date'] = pd.to_datetime(df_reviews['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_data_profiling(df_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_duplication(df_reviews)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
